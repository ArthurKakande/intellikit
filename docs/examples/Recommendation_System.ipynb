{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Levenshtein in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (0.25.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from Levenshtein) (3.8.1)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "     -------------------------------------- 163.3/163.3 kB 1.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.9.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.0.2)\n",
            "Collecting huggingface-hub>=0.15.1\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "     -------------------------------------- 388.9/388.9 kB 1.2 MB/s eta 0:00:00\n",
            "Collecting transformers<5.0.0,>=4.32.0\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "     ---------------------------------------- 8.8/8.8 MB 618.4 kB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.24.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from sentence_transformers) (9.2.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0)\n",
            "Collecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "     ------------------------------------ 172.0/172.0 kB 865.0 kB/s eta 0:00:00\n",
            "Requirement already satisfied: colorama in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2022.7.9)\n",
            "Collecting tokenizers<0.19,>=0.14\n",
            "  Downloading tokenizers-0.15.2-cp39-none-win_amd64.whl (2.2 MB)\n",
            "     ---------------------------------------- 2.2/2.2 MB 919.1 kB/s eta 0:00:00\n",
            "Collecting safetensors>=0.4.1\n",
            "  Downloading safetensors-0.4.2-cp39-none-win_amd64.whl (269 kB)\n",
            "     -------------------------------------- 269.7/269.7 kB 1.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2022.9.14)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\probook 450 g7\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.4)\n",
            "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2022.7.1\n",
            "    Uninstalling fsspec-2022.7.1:\n",
            "      Successfully uninstalled fsspec-2022.7.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.13.2\n",
            "    Uninstalling huggingface-hub-0.13.2:\n",
            "      Successfully uninstalled huggingface-hub-0.13.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.2\n",
            "    Uninstalling tokenizers-0.13.2:\n",
            "      Successfully uninstalled tokenizers-0.13.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.27.1\n",
            "    Uninstalling transformers-4.27.1:\n",
            "      Successfully uninstalled transformers-4.27.1\n",
            "Successfully installed fsspec-2024.3.1 huggingface-hub-0.22.2 safetensors-0.4.2 sentence_transformers-2.6.1 tokenizers-0.15.2 transformers-4.39.3\n"
          ]
        }
      ],
      "source": [
        "#!pip install Levenshtein\n",
        "#!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import intellikit as ik\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define your DataFrame on which the recommendation system is going to be based\n",
        "df = pd.DataFrame({\n",
        "    'feature1': ['apple', 'orange', 'banana', 'grape'],\n",
        "    'feature2': ['red', 'green', 'blue', 'yellow'],\n",
        "    'feature3': ['small', 'large', 'medium', 'small'],\n",
        "    'feature4': [1, 2, 3, 4],\n",
        "    'feature5': [10, 20, 30, 40]\n",
        "})\n",
        "\n",
        "#Define your query \n",
        "query = pd.DataFrame({\n",
        "    'feature1': ['apple'],\n",
        "    'feature2': ['yellow'],\n",
        "    'feature3': ['small'],\n",
        "    'feature4': [3],\n",
        "    'feature5': [30]\n",
        "\n",
        "})\n",
        "\n",
        "#Define you similarity calculation methods for your project\n",
        "hamming = ik.sim_hamming\n",
        "levenshtein = ik.sim_levenshtein\n",
        "ngrams = ik.sim_ngram\n",
        "abs_diff = ik.sim_difference\n",
        "\n",
        "# Assign the approriate similarity calculation functions to each feature\n",
        "similarity_functions = {\n",
        "    'feature1': hamming,\n",
        "    'feature2': levenshtein,\n",
        "    'feature3': ngrams,\n",
        "    'feature4': abs_diff,\n",
        "    'feature5': abs_diff\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   feature1  feature2  feature3  feature4  feature5\n",
            "0         0         5       1.0  0.333333  0.333333\n",
            "1         5         6       0.0  0.666667  0.666667\n",
            "2         5         5       0.0  1.000000  1.000000\n",
            "3         4         0       1.0  0.750000  0.750000\n"
          ]
        }
      ],
      "source": [
        "unweighted_results = [similarity_functions[feature](df, query, feature) for feature in df.columns]\n",
        "\n",
        "# Concatenate the resulting DataFrame columns along the rows\n",
        "result = pd.concat(unweighted_results, axis=1)\n",
        "\n",
        "print(result)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   feature1  feature2  feature3  feature4  feature5  weighted_total\n",
            "0      0.00       1.5      0.25  0.033333  0.033333        1.816667\n",
            "1      1.25       1.8      0.00  0.066667  0.066667        3.183333\n",
            "2      1.25       1.5      0.00  0.100000  0.100000        2.950000\n",
            "3      1.00       0.0      0.25  0.075000  0.075000        1.400000\n"
          ]
        }
      ],
      "source": [
        "#Applying the methods and weights and retreiving the top results\n",
        "# Define weights for each feature\n",
        "weights = {\n",
        "    'feature1': 0.25,\n",
        "    'feature2': 0.3,\n",
        "    'feature3': 0.25,\n",
        "    'feature4': 0.1,\n",
        "    'feature5': 0.1\n",
        "}\n",
        "\n",
        "# Multiply each column by its corresponding weight\n",
        "weighted_df = result * pd.Series(weights)\n",
        "\n",
        "# Add a new column for the total of the weighted columns\n",
        "weighted_df['weighted_total'] = weighted_df.sum(axis=1)\n",
        "\n",
        "print(weighted_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#You then go ahead and sort by the weighted total and retreived the top k ranked cases"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
